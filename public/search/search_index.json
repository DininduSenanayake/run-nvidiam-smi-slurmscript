{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Run <code>nvidia-smi</code> within a Slurm script","text":"<p>Add the following block to your Slurm script. </p> <ul> <li><code>STATS_INTERVAL=5</code> : This will gather profile data every 5 seconds </li> <li><code>STATS_FILE</code> : Make to include a valid path to write the .csv file which contains the profile data</li> <li><code>nvidia-smi --query-gpu=</code> : Most essential variables are <code>utilization.gpu,utilization.memory,memory.used,memory.total</code>. Feel free to remove the remainder</li> </ul> <p>terminal</p> <pre><code># GPU usage monitoring\nSTATS_INTERVAL=5\nSTATS_FILE=\"/path/to/save/the/output/file/${SLURM_JOB_ID}-gpu_stats.csv\"\nnvidia-smi --query-gpu=timestamp,uuid,clocks_throttle_reasons.sw_thermal_slowdown,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu,power.draw,clocks.current.sm \\\n--format=csv,nounits -l \"$STATS_INTERVAL\" -f \"$STATS_FILE\" &amp;\nsleep 20\n</code></pre> <p>For an example,</p> <p>terminal</p> <pre><code>#!/bin/bash -e\n#SBATCH --account           nesi12345\n#SBATCH --job-name          test-withsmi\n#SBATCH --time              06:30:00\n#SBATCH --cpus-per-task     3\n#SBATCH --mem               12G\n#SBATCH --gpus-per-node     A100:1\n#SBATCH --output            %j-%x.out\nmodule purge\nmodule load some-module\n\nSTATS_INTERVAL=5\nSTATS_FILE=\"/path/to/save/the/output/file/${SLURM_JOB_ID}-gpu_stats.csv\"\nnvidia-smi --query-gpu=timestamp,uuid,clocks_throttle_reasons.sw_thermal_slowdown,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu,power.draw,clocks.current.sm \\\n--format=csv,nounits -l \"$STATS_INTERVAL\" -f \"$STATS_FILE\" &amp;\nsleep 20#SBATCH --gpus-per-node     A100:1\nsome commands\n</code></pre>"},{"location":"#visualising-profile-data","title":"Visualising Profile data","text":"<p>Once the job was completed, following python script can be used to visualise the profile data acquired via <code>nvidia-smi</code></p> <ul> <li>For demonstration purposes, we will call the file with profile data 18957616-gpu_stats.csv and the figure to be generated gpu_profile_figure.png</li> </ul> <p>Visualise <code>nvidia-smi</code> profile data</p> <pre><code>#replace 18957616 with the corresponding JobID\nimport pandas as pd\ndset = pd.read_csv(\"18957616-gpu_stats.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\", sep=\", \", engine=\"python\")\ndset = dset.drop(columns=\"memory.total [MiB]\").dropna()\ndset[\"sw_thermal_slowdown\"] = dset[\"clocks_throttle_reasons.sw_thermal_slowdown\"].apply(lambda x: 0 if \"Not\" in x else 1)\naxes = dset.plot(subplots=True, figsize=(15, 10), grid=True)\naxes[0].figure.savefig(\"gpu_profile_figure.png\")\n</code></pre> <p></p>"}]}